import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.svm import OneClassSVM
from sklearn.metrics.pairwise import rbf_kernel
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import pyswarms as ps
import seaborn as sns

# ---------------------- Carregar CSV Gerado ---------------------
df = pd.read_csv("/content/2dados_envase_com_limites.csv")

# Mapear classes: em_controle -> 1, fora_controle -> -1
df['classe_num'] = df['classe'].map({'em_controle': 1, 'fora_controle': -1})

# ---------------------- Preparar dados ---------------------
X = df.drop(columns=['classe', 'classe_num']).values
Y = df['classe_num'].values

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# Separar treino/teste
X_train = X_pca[Y == 1]  # Treina s칩 com dados em controle
X_test = X_pca
Y_test = Y

# -------------------- Fun칞칚o de Avalia칞칚o para PSO --------------------
def evaluate_svdd(params):
    results = []
    for p in params:
        sigma, nu = p
        if sigma <= 0 or not (0.01 <= nu <= 0.5):
            results.append(1e6)
            continue
        gamma = 1 / (2 * sigma**2)
        try:
            model = OneClassSVM(kernel='rbf', gamma=gamma, nu=nu)
            model.fit(X_train)

            alphas = model.dual_coef_[0]
            sv = model.support_vectors_
            rho = np.dot(alphas, np.dot(rbf_kernel(sv, sv, gamma=gamma), alphas))

            kd_test = np.sqrt(1 - 2 * rbf_kernel(X_test, sv, gamma=gamma) @ alphas + rho)
            kd_train = np.sqrt(1 - 2 * rbf_kernel(X_train, sv, gamma=gamma) @ alphas + rho)
            h = np.percentile(kd_train, 95)

            preds = np.where(kd_test < h, 1, -1)
            acc = accuracy_score(Y_test, preds)
            results.append(1 - acc)
        except:
            results.append(1e6)
    return np.array(results)

# -------------------- Otimiza칞칚o com PSO --------------------
bounds = ([0.1, 0.01], [5.0, 0.5])
optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=2,
                                    options={'c1': 1.5, 'c2': 1.5, 'w': 0.8},
                                    bounds=bounds)
best_cost, best_params = optimizer.optimize(evaluate_svdd, iters=30)

# -------------------- Modelo final com melhores par칙metros --------------------
sigma_opt, nu_opt = best_params
gamma_opt = 1 / (2 * sigma_opt ** 2)

model = OneClassSVM(kernel='rbf', gamma=gamma_opt, nu=nu_opt)
model.fit(X_train)

alphas = model.dual_coef_[0]
sv = model.support_vectors_
rho = np.dot(alphas, np.dot(rbf_kernel(sv, sv, gamma=gamma_opt), alphas))

kd_test = np.sqrt(1 - 2 * rbf_kernel(X_test, sv, gamma=gamma_opt) @ alphas + rho)
kd_train = np.sqrt(1 - 2 * rbf_kernel(X_train, sv, gamma=gamma_opt) @ alphas + rho)

h = np.percentile(kd_train, 95)
preds = np.where(kd_test < h, 1, -1)

# -------------------- M칠tricas --------------------
acc = accuracy_score(Y_test, preds)
cm = confusion_matrix(Y_test, preds, labels=[1, -1])
tn, fp, fn, tp = cm.ravel()
fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
fnr = fn / (fn + tp) if (fn + tp) > 0 else 0
arl0 = 1 / fpr if fpr > 0 else float('inf')
arl1 = 1 / (1 - fnr) if fnr < 1 else float('inf')

# Exibir resultados
print("\n游늷 Par칙metros 칩timos via PSO:")
print(f"sigma = {sigma_opt:.4f}, nu = {nu_opt:.4f}, gamma = {gamma_opt:.4f}")
print(f"Acur치cia: {acc:.4f}")
print(f"FPR: {fpr:.4f}, FNR: {fnr:.4f}")
print(f"ARL0: {arl0:.2f}, ARL1: {arl1:.2f}")
print("\nMatriz de confus칚o:")
print(cm)
print("\nRelat칩rio:")
print(classification_report(Y_test, preds, target_names=["Em controle", "Fora de controle"]))

# -------------------- Gr치fico de Controle K --------------------
outliers = kd_test > h
plt.figure(figsize=(10, 6))
plt.plot(range(len(kd_test)), kd_test, 'bo-', label="Dist칙ncias ao Centro")
plt.axhline(y=h, color='red', linestyle='--', label="Limite de Controle (95%)")
plt.scatter(np.where(outliers)[0], kd_test[outliers], color='red', label="Fora de controle", zorder=5)
plt.title("Gr치fico K - SVDD com PSO aplicado  Simula칞칚o de Processo")
plt.xlabel("칈ndice da Amostra")
plt.ylabel("Dist칙ncia ao Centro do Kernel")
plt.legend()
plt.grid(True)
plt.show()

erros = np.where(preds != Y_test)[0]
print(f"\n游댌 칈ndices das amostras mal classificadas ({len(erros)} erros):")
print(erros)
